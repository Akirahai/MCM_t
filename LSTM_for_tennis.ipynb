{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "from model import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(\"cleaned_imputed_onehot_matches.csv\")\n",
    "M = matches['match_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.shuffle(M)\n",
    "train_matches = M[:int(0.9*len(M))]\n",
    "val_matches = M[int(0.9*len(M)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchs = val_matches\n",
    "lb = pd.read_csv(\"cleaned_imputed_onehot_matches.csv\")\n",
    "lb = lb[lb['match_id'].isin(matchs)]\n",
    "\n",
    "row = lb.iloc[1]\n",
    "id, point_no = row['match_id'], row['point_no']\n",
    "id, point_no\n",
    "\n",
    "point_no = f'point_{point_no}'\n",
    "with open(f\"data/{id}.json\", \"r\") as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(data[point_no].values())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(list(data[point_no].values())).T\n",
    "result = np.zeros((400,81))\n",
    "result[:A.shape[0],:A.shape[1]] = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id in M:\n",
    "    df = matches.loc[(matches['match_id'] == match_id) ,:]\n",
    "    features = df.columns[4:]\n",
    "    \n",
    "    dict = {}\n",
    "    for current_point in range(1, len(df) + 1):\n",
    "    # Filter data for the current point_no\n",
    "        current_data = df[df['point_no'] <= current_point]\n",
    "        \n",
    "        dict[f'point_{current_point}'] = {}\n",
    "        \n",
    "        for feature in features:\n",
    "            dict[f'point_{current_point}'][feature] = list(current_data[feature])\n",
    "    \n",
    "    file_path = f\"data/{match_id}.json\"\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(dict, file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset object for each point in match\n",
    "class Tennis_Dataset(Dataset):\n",
    "    def __init__(self, phase,  path_db, path_lb, matchs):\n",
    "        super(Tennis_Dataset, self).__init__()\n",
    "        self.phase = phase\n",
    "        \n",
    "        lb = pd.read_csv(path_lb)\n",
    "        lb = lb[lb['match_id'].isin(matchs)]\n",
    "        \n",
    "        self.path_db = path_db\n",
    "        self.result = lb\n",
    "        self.output = ['Alpha 1', 'Alpha 2']\n",
    "        \n",
    "        self.json_data = {}\n",
    "        for match_id in matchs:\n",
    "            json_file_path = os.path.join(self.path_db, f\"{match_id}.json\")\n",
    "            with open(json_file_path, \"r\") as file:\n",
    "                self.json_data[match_id] = json.load(file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.result)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.result.iloc[idx]\n",
    "        id, point_no = row['match_id'], row['point_no']\n",
    "        point_no = f'point_{point_no}'\n",
    "        \n",
    "        data = self.json_data[id]\n",
    "        point_data = data[point_no]\n",
    "        \n",
    "        A = np.array(list(data[point_no].values())).T\n",
    "        \n",
    "        result = np.zeros((400,81))\n",
    "        result[:A.shape[0],:A.shape[1]] = A\n",
    "        \n",
    "        labels = row[self.output].to_numpy(dtype=np.float32)\n",
    "        \n",
    "        return torch.from_numpy(result).float(), torch.from_numpy(labels).float()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_code = Tennis_Dataset('train', 'data', \"labels_alpha.csv\", train_matches[0:1])\n",
    "test_code_loader = DataLoader(train_dataset, batch_size= 3, shuffle=False)\n",
    "X, y = next(iter(test_code_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Tennis_Dataset('train', 'data', \"labels_alpha.csv\", train_matches)\n",
    "val_dataset = Tennis_Dataset('val', 'data', \"labels_alpha.csv\", val_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the lengths of the train and validation datasets\n",
    "train_dataset_length = len(train_dataset)\n",
    "val_dataset_length = len(val_dataset)\n",
    "\n",
    "# Calculate the percentage of validation dataset\n",
    "percent_validation = (val_dataset_length / (train_dataset_length + val_dataset_length)) * 100\n",
    "\n",
    "# Print the percentage of validation dataset\n",
    "print(f\"The percentage of validation dataset is: {percent_validation:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 200]          77,760\n",
      "       BatchNorm1d-2              [-1, 64, 200]             128\n",
      "              ReLU-3              [-1, 64, 200]               0\n",
      "         MaxPool1d-4              [-1, 64, 100]               0\n",
      "            Conv1d-5              [-1, 64, 100]          28,672\n",
      "       BatchNorm1d-6              [-1, 64, 100]             128\n",
      "              ReLU-7              [-1, 64, 100]               0\n",
      "           Dropout-8              [-1, 64, 100]               0\n",
      "            Conv1d-9              [-1, 64, 100]          28,672\n",
      "      BatchNorm1d-10              [-1, 64, 100]             128\n",
      "             ReLU-11              [-1, 64, 100]               0\n",
      "            Block-12              [-1, 64, 100]               0\n",
      "           Conv1d-13              [-1, 64, 100]          28,672\n",
      "      BatchNorm1d-14              [-1, 64, 100]             128\n",
      "             ReLU-15              [-1, 64, 100]               0\n",
      "          Dropout-16              [-1, 64, 100]               0\n",
      "           Conv1d-17              [-1, 64, 100]          28,672\n",
      "      BatchNorm1d-18              [-1, 64, 100]             128\n",
      "             ReLU-19              [-1, 64, 100]               0\n",
      "            Block-20              [-1, 64, 100]               0\n",
      "           Conv1d-21              [-1, 128, 50]          57,344\n",
      "      BatchNorm1d-22              [-1, 128, 50]             256\n",
      "             ReLU-23              [-1, 128, 50]               0\n",
      "          Dropout-24              [-1, 128, 50]               0\n",
      "           Conv1d-25              [-1, 128, 50]         114,688\n",
      "      BatchNorm1d-26              [-1, 128, 50]             256\n",
      "           Conv1d-27              [-1, 128, 50]           8,320\n",
      "      BatchNorm1d-28              [-1, 128, 50]             256\n",
      "             ReLU-29              [-1, 128, 50]               0\n",
      "            Block-30              [-1, 128, 50]               0\n",
      "           Conv1d-31              [-1, 128, 50]         114,688\n",
      "      BatchNorm1d-32              [-1, 128, 50]             256\n",
      "             ReLU-33              [-1, 128, 50]               0\n",
      "          Dropout-34              [-1, 128, 50]               0\n",
      "           Conv1d-35              [-1, 128, 50]         114,688\n",
      "      BatchNorm1d-36              [-1, 128, 50]             256\n",
      "             ReLU-37              [-1, 128, 50]               0\n",
      "            Block-38              [-1, 128, 50]               0\n",
      "           Conv1d-39              [-1, 256, 25]         229,376\n",
      "      BatchNorm1d-40              [-1, 256, 25]             512\n",
      "             ReLU-41              [-1, 256, 25]               0\n",
      "          Dropout-42              [-1, 256, 25]               0\n",
      "           Conv1d-43              [-1, 256, 25]         458,752\n",
      "      BatchNorm1d-44              [-1, 256, 25]             512\n",
      "           Conv1d-45              [-1, 256, 25]          33,024\n",
      "      BatchNorm1d-46              [-1, 256, 25]             512\n",
      "             ReLU-47              [-1, 256, 25]               0\n",
      "            Block-48              [-1, 256, 25]               0\n",
      "           Conv1d-49              [-1, 256, 25]         458,752\n",
      "      BatchNorm1d-50              [-1, 256, 25]             512\n",
      "             ReLU-51              [-1, 256, 25]               0\n",
      "          Dropout-52              [-1, 256, 25]               0\n",
      "           Conv1d-53              [-1, 256, 25]         458,752\n",
      "      BatchNorm1d-54              [-1, 256, 25]             512\n",
      "             ReLU-55              [-1, 256, 25]               0\n",
      "            Block-56              [-1, 256, 25]               0\n",
      "           Conv1d-57              [-1, 512, 13]         917,504\n",
      "      BatchNorm1d-58              [-1, 512, 13]           1,024\n",
      "             ReLU-59              [-1, 512, 13]               0\n",
      "          Dropout-60              [-1, 512, 13]               0\n",
      "           Conv1d-61              [-1, 512, 13]       1,835,008\n",
      "      BatchNorm1d-62              [-1, 512, 13]           1,024\n",
      "           Conv1d-63              [-1, 512, 13]         131,584\n",
      "      BatchNorm1d-64              [-1, 512, 13]           1,024\n",
      "             ReLU-65              [-1, 512, 13]               0\n",
      "            Block-66              [-1, 512, 13]               0\n",
      "           Conv1d-67              [-1, 512, 13]       1,835,008\n",
      "      BatchNorm1d-68              [-1, 512, 13]           1,024\n",
      "             ReLU-69              [-1, 512, 13]               0\n",
      "          Dropout-70              [-1, 512, 13]               0\n",
      "           Conv1d-71              [-1, 512, 13]       1,835,008\n",
      "      BatchNorm1d-72              [-1, 512, 13]           1,024\n",
      "             ReLU-73              [-1, 512, 13]               0\n",
      "            Block-74              [-1, 512, 13]               0\n",
      "AdaptiveAvgPool1d-75               [-1, 512, 1]               0\n",
      "AdaptiveMaxPool1d-76               [-1, 512, 1]               0\n",
      "           Linear-77                    [-1, 2]           2,050\n",
      "================================================================\n",
      "Total params: 8,806,594\n",
      "Trainable params: 8,806,594\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 3.80\n",
      "Params size (MB): 33.59\n",
      "Estimated Total Size (MB): 37.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from model import resnet_1d\n",
    "\n",
    "input_size = (81, 400)\n",
    "net = resnet_1d.ResNet18(num_classes=2, channels=81).to(device)\n",
    "# Print the summary\n",
    "summary(net, input_size=input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionRNN(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 3\n",
    "        \n",
    "        self.RNN = nn.RNN(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.5\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        \n",
    "        output, hn = self.RNN(x, h0)\n",
    "        out = self.linear(hn[0]).flatten()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "num_hidden_units = 16\n",
    "\n",
    "model_RNN = RegressionRNN(num_sensors= 81, hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_RNN.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2550, -0.0990, -0.2550, -0.0990, -0.2550, -0.0990],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RegressionRNN                            [2]                       --\n",
       "├─RNN: 1-1                               [1, 400, 16]              2,672\n",
       "├─Linear: 1-2                            [1, 2]                    34\n",
       "==========================================================================================\n",
       "Total params: 2,706\n",
       "Trainable params: 2,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.07\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.19\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model_RNN, (1, 400, 81), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionGRU(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 3\n",
    "        \n",
    "        self.GRU = nn.GRU(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.5\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        \n",
    "        output, hn = self.GRU(x, h0)\n",
    "        out = self.linear(hn[0]).flatten()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "num_hidden_units = 16\n",
    "\n",
    "model_GRU = RegressionGRU(num_sensors= 81, hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_GRU.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3504, -0.3662, -0.3504, -0.3662, -0.3504, -0.3662],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GRU(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RegressionGRU                            [2]                       --\n",
       "├─GRU: 1-1                               [1, 400, 16]              8,016\n",
       "├─Linear: 1-2                            [1, 2]                    34\n",
       "==========================================================================================\n",
       "Total params: 8,050\n",
       "Trainable params: 8,050\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 3.21\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.21\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model_GRU, (1, 400, 81), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 3\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.5\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        \n",
    "        output, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "num_hidden_units = 16\n",
    "\n",
    "model_LSTM = RegressionLSTM(num_sensors= 81, hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_LSTM.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1854, 0.0052, 0.1854, 0.0052, 0.1854, 0.0052],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RegressionLSTM                           [2]                       --\n",
       "├─LSTM: 1-1                              [1, 400, 16]              10,688\n",
       "├─Linear: 1-2                            [1, 2]                    34\n",
       "==========================================================================================\n",
       "Total params: 10,722\n",
       "Trainable params: 10,722\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.22\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model_LSTM, (1, 400, 81), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data_loader, model, loss_function):\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(model(X), y.reshape(-1)).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 0.00016669001650168665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Untrained test\\n--------\")\n",
    "test_model(train_loader, model, loss_function)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
